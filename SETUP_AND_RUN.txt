================================================================================
ControlSpeech + Mamba TTS - Setup Commands
================================================================================

# 1. Create conda environment
conda env create -f environment.yml
conda activate mambatts

# 2. Install additional packages
pip install mamba-ssm textgrid

# 3. Run setup script (downloads ~90GB, extracts audio, pairs transcripts)
#    This will take 30-60 minutes depending on internet speed
bash setup.sh

# 4. Install and run MFA (Montreal Forced Aligner)
conda install -c conda-forge montreal-forced-aligner
mfa model download acoustic english_mfa
mfa model download dictionary english_mfa

# Run MFA alignment (this will take several hours for 289k samples)
mfa align \
    VccmDataset/audio_extracted \
    english_mfa \
    english_mfa \
    VccmDataset/mfa_outputs

# 5. Preprocess dataset
#    NOTE: Use --audio_dir (extracted files) instead of --tarball
#    The tarball only contains ~56k files, but audio_extracted has all 418k files

# Recommended: Parallel preprocessing (faster)
python -m data_utils.preprocess_parallel \
    --csv_path VccmDataset/controlspeech_train.csv \
    --output_dir processed_data/ \
    --audio_dir VccmDataset/audio_extracted \
    --phoneme_vocab_path . \
    --cpu_workers 6 \
    --gpu_batch_size 32 \
    --io_workers 4

# Alternative: Serial preprocessing (slower, simpler)
python -m data_utils.preprocess \
    --csv_path VccmDataset/controlspeech_train.csv \
    --output_dir processed_data/ \
    --audio_dir VccmDataset/audio_extracted \
    --phoneme_vocab_path .

# 6. Train
python train.py --config config.yaml

# 7. Resume training (if interrupted)
python train.py --config config.yaml --resume checkpoints/last_checkpoint.pt

================================================================================
Dataset Summary (after setup.sh completes):
================================================================================
- Total audio files: ~418k WAV files
- Samples with transcripts: ~289k (matches CSV entries)
- Emotional datasets: ESD, MEAD, CREMA-D, TESS, RAVDESS, SAVEE, MESS (~42k)
- LibriTTS (non-emotional): ~247k samples
- Total download size: ~90GB
- Extracted size: ~110GB
================================================================================
NOTE: MFA alignments are REQUIRED. Training will fail with assertion error
if TextGrid files are not found in VccmDataset/mfa_outputs/
================================================================================
